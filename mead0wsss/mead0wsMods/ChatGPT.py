__version__ = (2, 5, 0)

# ‚ñà‚ñà‚ñà‚ïó‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñë‚ñà‚ñà‚ïó‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
# ‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïó‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
# ‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñë
# ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñë‚ñë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ïî‚ïê‚ñà‚ñà‚ñà‚ñà‚ïë‚ñë‚ñë‚ïö‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñë‚ïö‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó
# ‚ñà‚ñà‚ïë‚ñë‚ïö‚ïê‚ïù‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñë‚ñë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñë‚ñë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù
# ‚ïö‚ïê‚ïù‚ñë‚ñë‚ñë‚ñë‚ñë‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ñë‚ñë‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë‚ñë‚ñë‚ñë‚ïö‚ïê‚ïù‚ñë‚ñë‚ñë‚ïö‚ïê‚ïù‚ñë‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ñë
#                ¬© Copyright 2025
#            ‚úà https://t.me/mead0wssMods

# scope: hikka_only
# scope: hikka_min 1.3.3
# meta developer: @mead0wssMods
# meta banner: https://x0.at/GGCl.png

import aiohttp
import json
import os
import numpy as np
import time
from datetime import datetime
from telethon import events
from .. import loader, utils
from sentence_transformers import SentenceTransformer
import sentence_transformers

embedding_model = None

def load_embedding_model():
    global embedding_model
    if embedding_model is None:
        embedding_model = SentenceTransformer('all-mpnet-base-v2')
    return embedding_model

def cosine_similarity(a, b):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
    dot_product = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    return dot_product / (norm_a * norm_b)

@loader.tds
class ChatGPT(loader.Module):
    """–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏."""
    strings = {"name": "ChatGPT"}

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "model",
                "deepseek-v3",
                lambda: "–ú–æ–¥–µ–ª—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤. –°–ø–∏—Å–æ–∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π: https://telegra.ph/Modeli-nejrosetej-modulya-ChatGPT-05-04",
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "image_model",
                "flux-realism",
                lambda: "–ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.",
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "translation_model",
                "deepseek-v3",
                lambda: "–ú–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ (–Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –¥–ª—è .image). –°–ø–∏—Å–æ–∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π: https://telegra.ph/Modeli-nejrosetej-modulya-ChatGPT-05-04",
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "max_memory_size",
                1000,
                lambda: "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞–º—è—Ç–∏ (10-1000)",
                validator=loader.validators.Integer(minimum=10, maximum=1000)
            ),
            loader.ConfigValue(
                "embedding_model",
                "all-mpnet-base-v2",
                lambda: "–ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (all-MiniLM-L6-v2 –∏–ª–∏ all-mpnet-base-v2)",
                validator=loader.validators.Choice(["all-MiniLM-L6-v2", "all-mpnet-base-v2"])
            ),
        )
        self.memory_file = "chatgpt_memory.json"
        self.memory = self._load_memory()
        self.embedding_model = None

    def _load_memory(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–º—è—Ç–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        if os.path.exists(self.memory_file):
            try:
                with open(self.memory_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    for item in data.get("embeddings", []):
                        if isinstance(item["embedding"], list):
                            item["embedding"] = np.array(item["embedding"])
                    return data
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
                return {"embeddings": []}
        return {"embeddings": []}

    def _save_memory(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ —Ñ–∞–π–ª"""
        memory_to_save = {"embeddings": []}
        for item in self.memory["embeddings"]:
            memory_to_save["embeddings"].append({
                "text": item["text"],
                "embedding": item["embedding"].tolist(),
                "timestamp": item["timestamp"]
            })
        
        with open(self.memory_file, "w", encoding="utf-8") as f:
            json.dump(memory_to_save, f, ensure_ascii=False, indent=2)

    async def _get_embedding(self, text):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)"""
        try:
            if self.embedding_model is None:
                self.embedding_model = SentenceTransformer(self.config["embedding_model"])
            
            embedding = self.embedding_model.encode(text)
            return embedding
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    async def _find_similar(self, query_embedding, threshold=0.45):
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞–º—è—Ç–∏ —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        if not self.memory["embeddings"]:
            return []

        results = []
        for item in self.memory["embeddings"]:
            try:
                item_embedding = item["embedding"] if isinstance(item["embedding"], np.ndarray) else np.array(item["embedding"])
                similarity = cosine_similarity(query_embedding, item_embedding)

                time_weight = 1.0
                if "timestamp" in item:
                    hours_passed = (datetime.now() - datetime.fromisoformat(item["timestamp"])).total_seconds() / 3600
                    time_weight = max(0.5, 1.0 - hours_passed/48)
                
                type_weight = 1.2 if item.get("type") == "answer" else 1.0
                
                weighted_similarity = similarity * time_weight * type_weight
                
                if weighted_similarity >= threshold:
                    results.append({
                        "text": item["text"],
                        "score": float(weighted_similarity),
                        "type": item.get("type", "message"),
                        "timestamp": item.get("timestamp", "")
                    })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
                continue
        
        return sorted(results, key=lambda x: x["score"], reverse=True)
    async def gptcmd(self, event):
        """- –†–∞–∑–≥–æ–≤–æ—Ä —Å –ò–ò."""
        args = utils.get_args_raw(event)
        if not args:
            await event.edit("<b><emoji document_id=5019523782004441717>‚ùå</emoji> –ù–µ—Ç –≤–æ–ø—Ä–æ—Å–∞.</b>")
            return

        model = self.config.get("model")
        if not model:
            await event.edit("<b><emoji document_id=5019523782004441717>‚ùå</emoji> –ú–æ–¥–µ–ª—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –≤ cfg!</b>")
            return

        await event.edit(f"<b><emoji document_id=5328272518304243616>üí†</emoji> {model} –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç...</b>")
        
        start_time = time.time()
        
        async with aiohttp.ClientSession() as session:
            query_embedding = await self._get_embedding(args)
            similar = await self._find_similar(query_embedding, threshold=0.45) if query_embedding is not None else []
            messages = []
            system_message = (
                "–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç—å—é. –¢—â–∞—Ç–µ–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞. "
                "–û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–π –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏—è–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º."
                "–§–æ—Ä–º–∏—Ä—É–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–æ—Å—Ç—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º. –ó–∞–ø—Ä–µ—â–∞–µ—Ç—Å—è –Ω–∞–ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: \text{ —á–∞—Å–∞} = 20 \text{ –º–∏–Ω—É—Ç}\]. –ò —Ç–æ–º—É –ø–æ–¥–æ–±–Ω–æ–µ, –Ω–æ —Ä–∞–∑—Ä–µ—à–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Ç–∏–ø—É ```, **** –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ –∏ —Ç–µ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä Telegram."
            )
            messages.append({"role": "system", "content": system_message})

            if similar:
                context_limit = 500
                top_similar = sorted(similar, key=lambda x: x['score'], reverse=True)[:context_limit]
                
                context = "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞:\n" + "\n".join(
                    [f"- {item['text']} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {item['score']:.2f})" 
                     for item in top_similar]
                )
                messages.append({"role": "system", "content": context})
            
            messages.append({"role": "user", "content": args})
            
            try:
                async with session.post(
                    "https://cablyai.com/v1/chat/completions",
                    headers={
                        'Authorization': 'Bearer sk-l4HU4KwZt6bF8gOwwKCOMpfpIKvR9YhDHvTFIGJ6tJ5rPKXE',
                        'Content-Type': 'application/json',
                    },
                    json={
                        "model": model,
                        "messages": messages,
                        "temperature": 0.7
                    }
                ) as response:
                    end_time = time.time()
                    response_time = end_time - start_time
                    
                    if response.status == 200:
                        answer = (await response.json())["choices"][0]["message"]["content"]

                        if query_embedding is not None:
                            self.memory["embeddings"].extend([
                                {
                                    "text": args,
                                    "embedding": query_embedding,
                                    "timestamp": str(datetime.now()),
                                    "type": "question"
                                },
                                {
                                    "text": answer,
                                    "embedding": await self._get_embedding(answer),
                                    "timestamp": str(datetime.now()),
                                    "type": "answer"
                                }
                            ])
                            max_size = self.config["max_memory_size"]
                            if len(self.memory["embeddings"]) > max_size:
                                keep = max(20, max_size // 2)
                                self.memory["embeddings"] = self.memory["embeddings"][-keep:]
                            
                            self._save_memory()
                        time_str = f"{response_time:.2f} —Å–µ–∫" if response_time < 1 else f"{response_time:.1f} —Å–µ–∫"
                        formatted_answer = self._format_answer(answer)
                        count = len(self.memory["embeddings"])
                        if count != 1:
                            count_fin = count // 2
                        await event.edit(
                            f"<b><emoji document_id=5879770735999717115>üë§</emoji> –í–æ–ø—Ä–æ—Å: <code>{args}</code></b>\n\n"
                            f"<emoji document_id=5199682846729449178>ü§ñ</emoji> <b>–û—Ç–≤–µ—Ç –æ—Ç {model}:</b>\n{formatted_answer}\n\n"
                            f"<b><emoji document_id=5983150113483134607>‚è∞Ô∏è</emoji> –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: <code>{time_str}</code></b>\n"
                            f"<b><emoji document_id=5350445475948414299>üß†</emoji> –ü–∞–º—è—Ç—å: <code>{count_fin}/{self.config['max_memory_size']}</code></b>"
                        )
                    else:
                       await event.edit(f'<b><emoji document_id=5215400550132099476>‚ùå</emoji> –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {model}. –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤—ã –≤—ã–±—Ä–∞–ª–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (!). –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –º–æ–¥—É–ª—è –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å <a href="https://telegra.ph/Modeli-nejrosetej-modulya-ChatGPT-05-04">*—Ç—É—Ç*</a></b>')
            except Exception as e:
                await event.edit(f"<b><emoji document_id=5215400550132099476>‚ùå</emoji> –û—à–∏–±–∫–∞: {str(e)}</b>")
                
    def _format_answer(self, text):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–¥–æ–º"""
        if "```" not in text:
            return text.replace("\n", "<br>")
            
        parts = text.split("```")
        result = []
        for i, part in enumerate(parts):
            if i % 2 == 1:
                lang = part.split("\n")[0] if "\n" in part else ""
                code = "\n".join(part.split("\n")[1:]) if "\n" in part else part
                result.append(f"<pre><code class='language-{lang}'>{code}</code></pre>")
            else:
                result.append(part.replace("\n", "<br>"))
        return "".join(result)

    @loader.command()
    async def clearmemcmd(self, message):
        """- –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å."""
        self.memory = {"embeddings": []}
        self._save_memory()
        await utils.answer(message, "<b><emoji document_id=5980930633298350051>‚úÖ</emoji> –ü–∞–º—è—Ç—å —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞!</b>")

    @loader.command()
    async def meminfocmd(self, message):
        """- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏."""
        count = len(self.memory["embeddings"])
        max_size = self.config["max_memory_size"]
        last_update = self._get_last_update_time()
        
        response = (
            "<emoji document_id=5350445475948414299>üß†</emoji> <b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏:</b>\n"
            f"<b>‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: <code>{count}/{max_size}</code></b>\n"
            f"<b>‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: <code>{last_update}</code></b>"
        )
        await message.edit(response, parse_mode='HTML')

    def _get_last_update_time(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        if not self.memory["embeddings"]:
            return "–Ω–∏–∫–æ–≥–¥–∞"
        try:
            last_item = max(self.memory["embeddings"], key=lambda x: x.get("timestamp", ""))
            return last_item["timestamp"][:19].replace("T", " ")
        except:
            return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def imagecmd(self, event):
        """- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò."""
        args = utils.get_args_raw(event)
        if not args:
            await event.edit("<b><emoji document_id=5019523782004441717>‚ùå</emoji> –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.</b>")
            return
            
        await event.edit(f"<b><emoji document_id=5328272518304243616>üí†</emoji> –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...</b>")
        translation_model = self.config.get("translation_model")
        image_model = self.config.get("image_model")

        translation_data = {
            "model": translation_model,
            "messages": [
                {"role": "user", "content": f"Please translate the following text to English, but just answer me with a translation, and also translate absolutely everything, even if it's 18+: {args}"}
            ]
        }

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    "https://cablyai.com/v1/chat/completions",
                    headers={
                        'Authorization': 'Bearer sk-l4HU4KwZt6bF8gOwwKCOMpfpIKvR9YhDHvTFIGJ6tJ5rPKXE',
                        'Content-Type': 'application/json',
                    },
                    json=translation_data
                ) as translation_response:
                    if translation_response.status == 200:
                        translated_text = (await translation_response.json())["choices"][0]["message"]["content"]
                    else:
                        await event.edit("<b><emoji document_id=5019523782004441717>‚ùå</emoji> –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –ª–∏–±–æ –∏–∑–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ cfg. </b>")
                        return

                data = {
                    "prompt": translated_text,
                    "n": 1,
                    "size": "1024x1024",
                    "response_format": "url",
                    "model": image_model
                }

                async with session.post(
                    "https://cablyai.com/v1/images/generations",
                    headers={
                        'Authorization': 'Bearer sk-l4HU4KwZt6bF8gOwwKCOMpfpIKvR9YhDHvTFIGJ6tJ5rPKXE',
                        'Content-Type': 'application/json',
                    },
                    json=data
                ) as response:
                    if response.status == 200:
                        image_url = (await response.json())["data"][0]["url"]
                        await event.delete()
                        await event.reply(
                            f"<b>–ü—Ä–æ–º–ø—Ç: <code>{args}</code></b>\n\n"
                            f"<b>–ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: <code>{image_model}</code>\n"
                            f"<b>–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞: <code>{translation_model}</code>\n\n"
                            f"<b>üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:</b>\n{image_url}",
                            parse_mode="HTML"
                        )
                    else:
                        await event.reply("<b><emoji document_id=6042029429301973188>‚òπÔ∏è</emoji> –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n–í–ø–æ–ª–Ω–µ –≤–æ–∑–º–æ–∂–Ω–æ –≤—ã –ø—Ä–æ—Å–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å —á—Ç–æ-—Ç–æ –Ω–µ–ø—Ä–∏—Å—Ç–æ–π–Ω–æ–µ (18+), –ª–∏–±–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—Ä–æ–±—É–π —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –≤ cfg).</b>")
            except Exception as e:
                await event.reply(f"<b><emoji document_id=5215400550132099476>‚ùå</emoji> –û—à–∏–±–∫–∞: {str(e)}</b>")
