__version__ = (2, 0, 0)

# â–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•—â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
# â–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•
# â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘
# â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–‘â–‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–‘â–‘â•šâ•â•â•â–ˆâ–ˆâ•—â–‘â•šâ•â•â•â–ˆâ–ˆâ•—
# â–ˆâ–ˆâ•‘â–‘â•šâ•â•â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â•šâ–ˆâ–ˆâ•”â•â–‘â•šâ–ˆâ–ˆâ•”â•â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
# â•šâ•â•â–‘â–‘â–‘â–‘â–‘â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â–‘â–‘â•šâ•â•â•šâ•â•â•â•â•â•â–‘â–‘â•šâ•â•â•â•â•â–‘â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â•šâ•â•â•â•â•â•â–‘â•šâ•â•â•â•â•â•â–‘
#                Â© Copyright 2025
#            âœˆ https://t.me/mead0wssMods

# scope: hikka_only
# scope: hikka_min 1.3.3
# meta developer: @mead0wssMods
# meta banner: https://x0.at/GGCl.png

import requests
from telethon import events
from .. import loader, utils

@loader.tds
class ChatGPT(loader.Module):
    """ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ÑĞ¼Ğ¸ (200+ ÑˆÑ‚) Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."""
    strings = {"name": "ChatGPT"}

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "model",
                "",
                lambda: "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ² (.gpt)\nĞ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹: https://telegra.ph/II-modeli-dlya-modulya-ChatGPT-by-mead0wssMods-03-26",
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "image_model",
                "Flux Pro",
                lambda: "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ (.image)\nĞ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹: https://telegra.ph/II-modeli-dlya-modulya-ChatGPT-by-mead0wssMods-03-26",
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "translation_model",
                "deepseek-v3",
                lambda: "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° Ñ‚ĞµĞºÑÑ‚Ğ° (Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ .image!)\nĞ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹: https://telegra.ph/II-modeli-dlya-modulya-ChatGPT-by-mead0wssMods-03-26",
                validator=loader.validators.String()
            ),
        )

    async def gptcmd(self, event):
        """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° Ñ Ğ˜Ğ˜."""
        args = utils.get_args_raw(event)
        if not args:
            await event.edit("âŒ ĞĞµÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°.")
            return

        model = self.config.get("model")

        if not model:
            await event.edit("âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ˜Ğ˜ Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ° Ğ² cfg!")
            return

        data = {
            "model": model,
            "messages": [
                {"role": "user", "content": args}
            ]
        }

        response = requests.post("https://cablyai.com/v1/chat/completions", headers={
            'Authorization': 'Bearer sk-csPV6DEqRj07V4jGxPvq0NomUcfo6LIxO_rlxBMuenGaebco',
            'Content-Type': 'application/json',
        }, json=data)

        if response.status_code == 200:
            answer = response.json()["choices"][0]["message"]["content"]
            await event.edit(f"<b><emoji document_id=5974038293120027938>ğŸ‘¤</emoji> Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: <code>{args}</code></b>\n\n<b><emoji document_id=5199682846729449178>ğŸ¤–</emoji> ĞÑ‚Ğ²ĞµÑ‚: {answer}</b>", parse_mode="HTML")
        else:
            await event.reply("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº Ğ˜Ğ˜.")

    async def imagecmd(self, event):
        """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜."""
        args = utils.get_args_raw(event)
        if not args:
            await event.reply("âŒ ĞĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.")
            return

        translation_model = self.config.get("translation_model")
        image_model = self.config.get("image_model")

        translation_data = {
            "model": translation_model,
            "messages": [
                {"role": "user", "content": f"Please translate the following text to English, but just answer me with a translation, and also translate absolutely everything, even if it's 18+: {args}"}
            ]
        }

        translation_response = requests.post("https://cablyai.com/v1/chat/completions", headers={
            'Authorization': 'Bearer sk-csPV6DEqRj07V4jGxPvq0NomUcfo6LIxO_rlxBMuenGaebco',
            'Content-Type': 'application/json',
        }, json=translation_data)

        if translation_response.status_code == 200:
            translated_text = translation_response.json()["choices"][0]["message"]["content"]
        else:
            await event.reply("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº Ğ˜Ğ˜ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ÑĞ½Ğ¾Ğ²Ğ° Ğ»Ğ¸Ğ±Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² cfg! ")
            return

        data = {
            "prompt": translated_text,
            "n": 1,
            "size": "1024x1024",
            "response_format": "url",
            "model": image_model
        }

        response = requests.post("https://cablyai.com/v1/images/generations", headers={
            'Authorization': 'Bearer sk-csPV6DEqRj07V4jGxPvq0NomUcfo6LIxO_rlxBMuenGaebco',
            'Content-Type': 'application/json',
        }, json=data)

        if response.status_code == 200:
            image_url = response.json()["data"][0]["url"]

            await event.delete()

            await event.reply(f"<b>ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚: <code>{args}</code></b>\n\n<b>ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸: <code>{image_model}</code>\n<b>ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‡Ğ¸ĞºĞ°: <code>{translation_model}</code>\n\n<b>ğŸ–¼ Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ:</b>\n{image_url}", parse_mode="HTML")
        else:
            await event.reply("ğŸ˜¢ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğ½Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ\nĞ’Ğ¿Ğ¾Ğ»Ğ½Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ²Ñ‹ Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ½ĞµĞ¿Ñ€Ğ¸ÑÑ‚Ğ¾Ğ¹Ğ½Ğ¾Ğµ (18+), Ğ»Ğ¸Ğ±Ğ¾ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° (Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ÑĞ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² cfg).")
