#  This file is part of SenkoGuardianModules
#  Copyright (c) 2025 Senko
#  This software is released under the MIT License.
#  https://opensource.org/licenses/MIT

__version__ = (5, 0, 0) # –∞—Å–∞–ª–∞–º–∞–ª–µ–π–∫—É–º —Ç–µ–º –∫—Ç–æ –∫–æ–¥ —Å–º–æ—Ç—Ä–∏—Ç –æ—Ç –º–µ–Ω—è (–∫—Å—Ç–∞ –¥–ª—è —á–µ–≥–æ —Å–º–æ—Ç—Ä–∏—Ç–µ?) (—è –∑–∞–µ–±–∞–ª—Å—è, –æ—à–∏–±–æ–∫ –±—ã–ª–æ –¥–æ—Ö—É–∏—â–µ)

# meta developer: @SenkoGuardianModules

#  .------. .------. .------. .------. .------. .------.
#  |S.--. | |E.--. | |N.--. | |M.--. | |O.--. | |D.--. |
#  | :/\: | | :/\: | | :(): | | :/\: | | :/\: | | :/\: |
#  | :\/: | | :\/: | | ()() | | :\/: | | :\/: | | :\/: |
#  | '--'S| | '--'E| | '--'N| | '--'M| | '--'O| | '--'D|
#  `------' `------' `------' `------' `------' `------'

import re
import os
import io
import random
import socket
import asyncio
import logging
import aiohttp
import tempfile
from markdown_it import MarkdownIt
import pytz
from telethon import types
from telethon.tl import types as tl_types
from telethon.tl.types import Message, DocumentAttributeFilename
from telethon.utils import get_display_name, get_peer_id
from telethon.errors.rpcerrorlist import MessageTooLongError, ChatAdminRequiredError
from telethon.errors.rpcerrorlist import UserNotParticipantError, ChannelPrivateError
import google.ai.generativelanguage as glm
import google.api_core.exceptions as google_exceptions
import google.generativeai as genai
from .. import loader, utils
from ..inline.types import InlineCall

# requires: google-generativeai google-api-core pytz markdown_it_py

logger = logging.getLogger(__name__)

DB_HISTORY_KEY = "gemini_conversations_v4"
DB_GAUTO_HISTORY_KEY = "gemini_gauto_conversations_v1"
DB_IMPERSONATION_KEY = "gemini_impersonation_chats"
GEMINI_TIMEOUT = 840
MAX_FFMPEG_SIZE = 90 * 1024 * 1024

@loader.tds
class Gemini(loader.Module):
    """–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini AI.(—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ video/image/audio)"""
    strings = {
        "name": "Gemini",
        "cfg_api_key_doc": "API –∫–ª—é—á –¥–ª—è Google Gemini AI.",
        "cfg_model_name_doc": "–ú–æ–¥–µ–ª—å Gemini.",
        "cfg_buttons_doc": "–í–∫–ª—é—á–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∫–Ω–æ–ø–∫–∏.",
        "cfg_system_instruction_doc": "–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (–ø—Ä–æ–º–ø—Ç) –¥–ª—è Gemini.",
        "cfg_max_history_length_doc": "–ú–∞–∫—Å. –∫–æ–ª-–≤–æ –ø–∞—Ä '–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç' –≤ –ø–∞–º—è—Ç–∏ (0 - –±–µ–∑ –ª–∏–º–∏—Ç–∞).",
        "cfg_timezone_doc": "–í–∞—à —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å. –°–ø–∏—Å–æ–∫: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones",
        "cfg_proxy_doc": "–ü—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫. –§–æ—Ä–º–∞—Ç: http://user:pass@host:port",
        "cfg_impersonation_prompt_doc": "–ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞. {my_name} –∏ {chat_history} –±—É–¥—É—Ç –∑–∞–º–µ–Ω–µ–Ω—ã.",
        "cfg_impersonation_history_limit_doc": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞.",
        "cfg_impersonation_reply_chance_doc": "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ gauto (–æ—Ç 0.0 –¥–æ 1.0). 0.2 = 20% —à–∞–Ω—Å.",
        "no_api_key": '‚ùóÔ∏è <b>Api –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.</b>\n–ü–æ–ª—É—á–∏—Ç—å Api –∫–ª—é—á –º–æ–∂–Ω–æ <a href="https://aistudio.google.com/app/apikey">–∑–¥–µ—Å—å</a>.\n <b>–ü–æ—Å—Ç–∞–≤–∏—Ç—å –∫–ª—é—á —Å—é–¥–∞:</b> <code>.cfg gemini api_key</code>',
        "no_prompt_or_media": "‚ö†Ô∏è <i>–ù—É–∂–µ–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞/—Ñ–∞–π–ª.</i>",
        "processing": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–û–±—Ä–∞–±–æ—Ç–∫–∞...</b>",
        "api_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ API Google Gemini:</b>\n<code>{}</code>",
        "api_timeout": f"‚ùóÔ∏è <b>–¢–∞–π–º–∞—É—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini API ({GEMINI_TIMEOUT} —Å–µ–∫).</b>",
        "blocked_error": "üö´ <b>–ó–∞–ø—Ä–æ—Å/–æ—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω.</b>\n<code>{}</code>",
        "generic_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞:</b>\n<code>{}</code>",
        "question_prefix": "üí¨ <b>–ó–∞–ø—Ä–æ—Å:</b>",
        "response_prefix": "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>Gemini:</b>",
        "unsupported_media_type": "‚ö†Ô∏è <b>–§–æ—Ä–º–∞—Ç –º–µ–¥–∏–∞ ({}) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.</b>",
        "memory_status": "üß† [{}/{}]",
        "memory_status_unlimited": "üß† [{}/‚àû]",
        "memory_cleared": "üßπ <b>–ü–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.</b>",
        "memory_cleared_gauto": "üßπ <b>–ü–∞–º—è—Ç—å gauto –≤ —ç—Ç–æ–º —á–∞—Ç–µ –æ—á–∏—â–µ–Ω–∞.</b>",
        "no_memory_to_clear": "‚ÑπÔ∏è <b>–í —ç—Ç–æ–º —á–∞—Ç–µ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏.</b>",
        "no_gauto_memory_to_clear": "‚ÑπÔ∏è <b>–í —ç—Ç–æ–º —á–∞—Ç–µ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ gauto.</b>",
        "memory_chats_title": "üß† <b>–ß–∞—Ç—ã —Å –∏—Å—Ç–æ—Ä–∏–µ–π ({}):</b>",
        "memory_chat_line": "  ‚Ä¢ {} (<code>{}</code>)",
        "no_memory_found": "‚ÑπÔ∏è –ü–∞–º—è—Ç—å Gemini –ø—É—Å—Ç–∞.",
        "media_reply_placeholder": "[–æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞]",
        "btn_clear": "üßπ –û—á–∏—Å—Ç–∏—Ç—å",
        "btn_regenerate": "üîÑ –î—Ä—É–≥–æ–π –æ—Ç–≤–µ—Ç",
        "no_last_request": "–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.",
        "memory_fully_cleared": "üßπ <b>–í—Å—è –ø–∞–º—è—Ç—å Gemini –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞ (–∑–∞—Ç—Ä–æ–Ω—É—Ç–æ {} —á–∞—Ç–æ–≤).</b>",
        "gauto_memory_fully_cleared": "üßπ <b>–í—Å—è –ø–∞–º—è—Ç—å gauto –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞ (–∑–∞—Ç—Ä–æ–Ω—É—Ç–æ {} —á–∞—Ç–æ–≤).</b>",
        "no_memory_to_fully_clear": "‚ÑπÔ∏è <b>–ü–∞–º—è—Ç—å Gemini –∏ —Ç–∞–∫ –ø—É—Å—Ç–∞.</b>",
        "no_gauto_memory_to_fully_clear": "‚ÑπÔ∏è <b>–ü–∞–º—è—Ç—å gauto –∏ —Ç–∞–∫ –ø—É—Å—Ç–∞.</b>",
        "response_too_long": "–û—Ç–≤–µ—Ç Gemini –±—ã–ª —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞.",
        "gclear_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b> <code>.gclear [auto]</code>",
        "gres_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b> <code>.gres [auto]</code>",
        "auto_mode_on": "üé≠ <b>–†–µ–∂–∏–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞ –≤–∫–ª—é—á–µ–Ω –≤ —ç—Ç–æ–º —á–∞—Ç–µ.</b>\n–Ø –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {}%.",
        "auto_mode_off": "üé≠ <b>–†–µ–∂–∏–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞ –≤—ã–∫–ª—é—á–µ–Ω –≤ —ç—Ç–æ–º —á–∞—Ç–µ.</b>",
        "auto_mode_chats_title": "üé≠ <b>–ß–∞—Ç—ã —Å –∞–∫—Ç–∏–≤–Ω—ã–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–æ–º ({}):</b>",
        "no_auto_mode_chats": "‚ÑπÔ∏è –ù–µ—Ç —á–∞—Ç–æ–≤ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º —Ä–µ–∂–∏–º–æ–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞.",
        "auto_mode_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b> <code>.gauto on/off</code>",
        "gch_usage": "‚ÑπÔ∏è <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:</b>\n<code>.gch <–∫–æ–ª-–≤–æ> <–≤–æ–ø—Ä–æ—Å></code>\n<code>.gch <id —á–∞—Ç–∞> <–∫–æ–ª-–≤–æ> <–≤–æ–ø—Ä–æ—Å></code>",
        "gch_processing": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é {} —Å–æ–æ–±—â–µ–Ω–∏–π...</b>",
        "gch_result_caption": "–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {} —Å–æ–æ–±—â–µ–Ω–∏–π",
        "gch_result_caption_from_chat": "–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ <b>{}</b>",
        "gch_invalid_args": "‚ùóÔ∏è <b>–ù–µ–≤–µ—Ä–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.</b>\n{}",
        "gch_chat_error": "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —á–∞—Ç—É</b> <code>{}</code>: <i>{}</i>",
    }
    TEXT_MIME_TYPES = {
        "text/plain", "text/markdown", "text/html", "text/css", "text/csv",
        "application/json", "application/xml", "application/x-python", "text/x-python",
        "application/javascript", "application/x-sh",
    }
    def __init__(self):
        self.config=loader.ModuleConfig(
            loader.ConfigValue("api_key", "", self.strings["cfg_api_key_doc"], validator=loader.validators.Hidden()),
            loader.ConfigValue("model_name", "gemini-2.5-flash", self.strings["cfg_model_name_doc"]),
            loader.ConfigValue("interactive_buttons", True, self.strings["cfg_buttons_doc"], validator=loader.validators.Boolean()),
            loader.ConfigValue("system_instruction", "", self.strings["cfg_system_instruction_doc"], validator=loader.validators.String()),
            loader.ConfigValue("max_history_length", 800, self.strings["cfg_max_history_length_doc"], validator=loader.validators.Integer(minimum=0)),
            loader.ConfigValue("timezone", "Europe/Moscow", self.strings["cfg_timezone_doc"]),
            loader.ConfigValue("proxy", "", self.strings["cfg_proxy_doc"]),
            loader.ConfigValue(
                "impersonation_prompt",
                (
                    "–¢—ã ‚Äî —ç—Ç–æ —è, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å Telegram –ø–æ –∏–º–µ–Ω–∏ {my_name}. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å –≤ —á–∞—Ç–µ –æ—Ç –º–æ–µ–≥–æ –∏–º–µ–Ω–∏, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö. "
                    "–í–µ–¥–∏ —Å–µ–±—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –∞ –Ω–µ –∫–∞–∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ù–µ –ø—Ä–∏–∑–Ω–∞–≤–∞–π—Å—è, —á—Ç–æ —Ç—ã ‚Äî –ò–ò, –¥–∞–∂–µ –µ—Å–ª–∏ —Ç–µ–±—è —Å–ø—Ä–æ—Å—è—Ç –Ω–∞–ø—Ä—è–º—É—é. "
                    "–¢–≤–æ—è –ª–∏—á–Ω–æ—Å—Ç—å: [–ó–¥–µ—Å—å –æ–ø–∏—à–∏—Ç–µ —Å–≤–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä: –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, —Å–µ—Ä—å–µ–∑–Ω—ã–π, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —Ç.–¥.].\n"
                    "–ü—Ä–∞–≤–∏–ª–∞:\n"
                    "- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ù–µ –ø–∏—à–∏ –¥–ª–∏–Ω–Ω—ã–µ —ç—Å—Å–µ.\n"
                    "- –ò—Å–ø–æ–ª—å–∑—É–π –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —è–∑—ã–∫, –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–Ω–≥, –µ—Å–ª–∏ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ.\n"
                    "- –ù–µ –æ—Ç–≤–µ—á–∞–π –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –ø—Ä–æ—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–∏–ø–∞ '–æ–∫', '–∞–≥–∞', '—Å–ø—Å'.\n"
                    "- –ï—Å–ª–∏ –∫—Ç–æ-—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –º–µ–¥–∏–∞ (—Å—Ç–∏–∫–µ—Ä, —Ñ–æ—Ç–æ), –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–π –Ω–∞ –Ω–µ–≥–æ, –∫–∞–∫ –±—ã —ç—Ç–æ —Å–¥–µ–ª–∞–ª —á–µ–ª–æ–≤–µ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–ª–æ–ª', '–æ—Ä—É', '–∂–∏–∑–∞', '–∫—Ä–∞—Å–∏–≤–æ').\n"
                    "- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏ –∫–∞–≤—ã—á–∫–∏. –ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞.\n\n"
                    "–í–æ—Ç –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —Ç–æ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å. –û—Ç–≤–µ—Ç—å –Ω–∞ –Ω–µ–≥–æ.\n\n"
                    "–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê:\n{chat_history}\n\n{my_name}:"
                ),
                self.strings["cfg_impersonation_prompt_doc"],
                validator=loader.validators.String(),
            ),
            loader.ConfigValue("impersonation_history_limit", 80, self.strings["cfg_impersonation_history_limit_doc"], validator=loader.validators.Integer(minimum=5, maximum=100)),
            loader.ConfigValue("impersonation_reply_chance", 0.25, self.strings["cfg_impersonation_reply_chance_doc"], validator=loader.validators.Float(minimum=0.0, maximum=1.0)),
        )
        self.conversations={}
        self.gauto_conversations={}
        self.last_requests={}
        self.impersonation_chats=set()
        self._lock=asyncio.Lock()
        self.memory_disabled_chats=set()

    @loader.command()
    async def g(self, message: Message):
        """[—Ç–µ–∫—Å—Ç –∏–ª–∏ reply] ‚Äî —Å–ø—Ä–æ—Å–∏—Ç—å —É Gemini. –ú–æ–∂–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Å—ã–ª–∫–∏."""
        clean_args=utils.get_args_raw(message)
        reply=await message.get_reply_message()
        use_url_context=False
        text_to_check=clean_args
        if reply and reply.text: text_to_check+=" " + reply.text
        if re.search(r'https?://\S+', text_to_check): use_url_context=True
        status_msg=await utils.answer(message, self.strings["processing"])
        parts, warnings=await self._prepare_parts(message, custom_text=clean_args)
        if warnings and status_msg:
            warning_text="\n".join(warnings)
            try: await status_msg.edit(f"{status_msg.text}\n\n{warning_text}")
            except MessageTooLongError: await message.reply(warning_text)
        if not parts:
            err_msg=self.strings["no_prompt_or_media"]
            if status_msg: await utils.answer(status_msg, err_msg)
            return
        await self._send_to_gemini(message=message, parts=parts, status_msg=status_msg, use_url_context=use_url_context, display_prompt=clean_args or None)

    @loader.command()
    async def gch(self, message: Message):
        """<[id —á–∞—Ç–∞]> <–∫–æ–ª-–≤–æ> <–≤–æ–ø—Ä–æ—Å> - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞."""
        args=utils.get_args_raw(message).split(maxsplit=2)
        target_chat_id, count_str, user_prompt=None, None, None
        if len(args) == 2:
            target_chat_id=utils.get_chat_id(message)
            count_str, user_prompt=args[0], args[1]
        elif len(args) == 3:
            try:
                target_chat_id=int(args[0])
                count_str, user_prompt=args[1], args[2]
            except ValueError:
                return await utils.answer(message, self.strings["gch_invalid_args"].format("ID —á–∞—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º."))
        else:
            return await utils.answer(message, self.strings["gch_usage"])
        try:
            count=int(count_str)
            if count<=0 or count > 20000: raise ValueError
        except ValueError:
            return await utils.answer(message, self.strings["gch_invalid_args"].format(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º –æ—Ç 1 –¥–æ 20000. –í—ã –≤–≤–µ–ª–∏: <code>{utils.escape_html(count_str)}</code>"))
        status_msg=await utils.answer(message, self.strings["gch_processing"].format(count))
        try:
            entity=await self.client.get_entity(target_chat_id)
            chat_name=utils.escape_html(get_display_name(entity))
            chat_log=await self._get_recent_chat_text(target_chat_id, count=count, skip_last=False)
        except (ValueError, TypeError, ChatAdminRequiredError, UserNotParticipantError, ChannelPrivateError) as e:
            return await utils.answer(status_msg, self.strings["gch_chat_error"].format(target_chat_id, e.__class__.__name__))
        except Exception as e:
            return await utils.answer(status_msg, self.strings["gch_chat_error"].format(target_chat_id, e))
        full_prompt=(
            f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
            f"–¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Å–Ω–æ–≤–∞–Ω –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏.\n\n"
            f"–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: \"{user_prompt}\"\n\n"
            f"–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê:\n---\n{chat_log}\n---"
        )
        try:
            if not self.config["api_key"]:
                await utils.answer(status_msg, self.strings['no_api_key']); return
            genai.configure(api_key=self.config["api_key"])
            model=genai.GenerativeModel(self.config["model_name"], safety_settings=self.safety_settings)
            response=await asyncio.wait_for(model.generate_content_async(full_prompt), timeout=GEMINI_TIMEOUT)
            result_text=response.text
            header = self.strings["gch_result_caption_from_chat"].format(count, chat_name) if target_chat_id != utils.get_chat_id(message) else self.strings["gch_result_caption"].format(count)
            question_html=f"<blockquote expandable>{utils.escape_html(user_prompt)}</blockquote>"
            response_html=self._markdown_to_html(result_text)
            formatted_body=self._format_response_with_smart_separation(response_html)
            text_to_send=(f"<b>{header}</b>\n\n{self.strings['question_prefix']}\n{question_html}\n\n{self.strings['response_prefix']}\n{formatted_body}")
            if len(text_to_send) > 4096:
                file_content=(f"–í–æ–ø—Ä–æ—Å: {user_prompt}\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n–û—Ç–≤–µ—Ç Gemini –Ω–∞ –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ '{chat_name}':\n{result_text}")
                file=io.BytesIO(file_content.encode("utf-8"))
                file.name=f"analysis_{target_chat_id}.txt"
                await status_msg.delete()
                await message.reply(file=file, caption=f"üìù {header}")
            else:
                await utils.answer(status_msg, text_to_send)
        except Exception as e:
            await utils.answer(status_msg, self._handle_error(e))

    @loader.command()
    async def gauto(self, message: Message):
        """<on/off> ‚Äî –í–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞ –≤ —á–∞—Ç–µ."""
        args=utils.get_args_raw(message)
        chat_id=utils.get_chat_id(message)
        if args=="on":
            self.impersonation_chats.add(chat_id)
            self.db.set(self.strings["name"], DB_IMPERSONATION_KEY, list(self.impersonation_chats))
            await utils.answer(message, self.strings["auto_mode_on"].format(int(self.config["impersonation_reply_chance"]*100)))
        elif args=="off":
            self.impersonation_chats.discard(chat_id)
            self.db.set(self.strings["name"], DB_IMPERSONATION_KEY, list(self.impersonation_chats))
            await utils.answer(message, self.strings["auto_mode_off"])
        else:
            await utils.answer(message, self.strings["auto_mode_usage"])

    @loader.command()
    async def gautochats(self, message: Message):
        """‚Äî –ü–æ–∫–∞–∑–∞—Ç—å —á–∞—Ç—ã —Å –∞–∫—Ç–∏–≤–Ω—ã–º —Ä–µ–∂–∏–º–æ–º –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞."""
        if not self.impersonation_chats:
            await utils.answer(message, self.strings["no_auto_mode_chats"])
            return
        out=[self.strings["auto_mode_chats_title"].format(len(self.impersonation_chats))]
        for chat_id in self.impersonation_chats:
            try:
                entity=await self.client.get_entity(chat_id)
                name=utils.escape_html(get_display_name(entity))
                out.append(self.strings["memory_chat_line"].format(name, chat_id))
            except Exception:
                out.append(self.strings["memory_chat_line"].format("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —á–∞—Ç", chat_id))
        await utils.answer(message, "\n".join(out))

    @loader.command()
    async def gclear(self, message: Message):
        """[auto] ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –≤ —á–∞—Ç–µ. auto –¥–ª—è –ø–∞–º—è—Ç–∏ gauto."""
        args=utils.get_args_raw(message)
        chat_id=utils.get_chat_id(message)
        if args=="auto":
            if str(chat_id) in self.gauto_conversations:
                self._clear_history(chat_id, gauto=True)
                await utils.answer(message, self.strings["memory_cleared_gauto"])
            else:
                await utils.answer(message, self.strings["no_gauto_memory_to_clear"])
        elif not args:
            if str(chat_id) in self.conversations:
                self._clear_history(chat_id, gauto=False)
                await utils.answer(message, self.strings["memory_cleared"])
            else:
                await utils.answer(message, self.strings["no_memory_to_clear"])
        else:
            await utils.answer(message, self.strings["gclear_usage"])

    @loader.command()
    async def gmemdel(self, message: Message):
        """[N] ‚Äî —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–∞–º—è—Ç–∏."""
        args=utils.get_args_raw(message)
        try: n=int(args) if args else 1
        except Exception: n=1
        chat_id=utils.get_chat_id(message)
        hist=self._get_structured_history(chat_id)
        elements_to_remove=n*2
        if n > 0 and len(hist) >= elements_to_remove:
            hist=hist[:-elements_to_remove]
            self.conversations[str(chat_id)]=hist
            self._save_history_sync()
            await utils.answer(message, f"üßπ –£–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö <b>{n}</b> –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–∞–º—è—Ç–∏.")
        else:
            await utils.answer(message, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")

    @loader.command()
    async def gmemchats(self, message: Message):
        """‚Äî –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç—å—é (–∏–º—è –∏ ID)."""
        if not self.conversations:
            await utils.answer(message, self.strings["no_memory_found"]); return
        out=[self.strings["memory_chats_title"].format(len(self.conversations))]
        shown=set()
        for chat_id_str in list(self.conversations.keys()):
            if not chat_id_str or not str(chat_id_str).isdigit():
                del self.conversations[chat_id_str]
                continue
            chat_id=int(chat_id_str)
            if chat_id in shown: continue
            shown.add(chat_id)
            try:
                entity=await self.client.get_entity(chat_id)
                name=get_display_name(entity)
            except Exception: name=f"Unknown ({chat_id})"
            out.append(self.strings["memory_chat_line"].format(name, chat_id))
        self._save_history_sync()
        if len(out)==1:
            await utils.answer(message, self.strings["no_memory_found"]); return
        await utils.answer(message, "\n".join(out))

    @loader.command()
    async def gmemexport(self, message: Message):
        """[auto] ‚Äî —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞. auto –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ gauto."""
        args=utils.get_args_raw(message)
        gauto_mode=args=="auto"
        chat_id=utils.get_chat_id(message)
        hist=self._get_structured_history(chat_id, gauto=gauto_mode)
        if not hist: return await utils.answer(message, "–ò—Å—Ç–æ—Ä–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –ø—É—Å—Ç–∞.")
        user_ids={e.get("user_id") for e in hist if e.get("role")=="user" and e.get("user_id")}
        user_names={None: None}
        for uid in user_ids:
            if not uid: continue
            try:
                entity=await self.client.get_entity(uid)
                user_names[uid]=get_display_name(entity)
            except Exception: user_names[uid]=f"Deleted Account ({uid})"
        import json
        def make_serializable(entry):
            entry=dict(entry)
            user_id=entry.get("user_id")
            if user_id: entry["user_name"]=user_names.get(user_id)
            if hasattr(user_id, "user_id"): entry["user_id"]=user_id.user_id
            elif isinstance(user_id, (int, str)): entry["user_id"]=user_id
            elif user_id is not None: entry["user_id"]=str(user_id)
            else: entry["user_id"]=None
            if "message_id" in entry and entry["message_id"] is not None:
                try: entry["message_id"]=int(entry["message_id"])
                except (ValueError, TypeError): entry["message_id"]=None
            return entry
        serializable_hist=[make_serializable(e) for e in hist]
        data=json.dumps(serializable_hist, ensure_ascii=False, indent=2)
        file_suffix="gauto_history" if gauto_mode else "history"
        file=io.BytesIO(data.encode("utf-8"))
        file.name=f"gemini_{file_suffix}_{chat_id}.json"
        caption="–≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ gauto Gemini" if gauto_mode else "–≠–∫—Å–ø–æ—Ä—Ç –ø–∞–º—è—Ç–∏ Gemini"
        await self.client.send_file(message.chat_id, file, caption=caption)

    @loader.command()
    async def gmemimport(self, message: Message):
        """[auto] ‚Äî –∏–º–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞ (–æ—Ç–≤–µ—Ç–æ–º). auto –¥–ª—è gauto."""
        reply=await message.get_reply_message()
        if not reply or not reply.document: return await utils.answer(message, "–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ json-—Ñ–∞–π–ª —Å –ø–∞–º—è—Ç—å—é.")
        args=utils.get_args_raw(message)
        gauto_mode=args=="auto"
        file=io.BytesIO()
        await self.client.download_media(reply, file)
        file.seek(0)
        MAX_IMPORT_SIZE=6 * 1024 * 1024
        if file.getbuffer().nbytes > MAX_IMPORT_SIZE: return await utils.answer(message, f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>{MAX_IMPORT_SIZE // (1024*1024)} –ú–ë).")
        import json
        try:
            hist=json.load(file)
            if not isinstance(hist, list): raise ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—Ä–∏–∏.")
            new_hist=[]
            for e in hist:
                if not isinstance(e, dict) or "role" not in e or "content" not in e: raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏.")
                entry={"role": e["role"], "type": e.get("type", "text"), "content": e["content"], "date": e.get("date")}
                if e["role"]=="user":
                    entry["user_id"]=e.get("user_id")
                    entry["message_id"]=e.get("message_id")
                new_hist.append(entry)
            chat_id=utils.get_chat_id(message)
            conversations=self.gauto_conversations if gauto_mode else self.conversations
            conversations[str(chat_id)]=new_hist
            self._save_history_sync(gauto=gauto_mode)
            await utils.answer(message, "–ü–∞–º—è—Ç—å —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞.")
        except Exception as e:
            await utils.answer(message, f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")

    @loader.command()
    async def gmemfind(self, message: Message):
        """[—Å–ª–æ–≤–æ] ‚Äî –ü–æ–∏—Å–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É –∏–ª–∏ —Ñ—Ä–∞–∑–µ."""
        args=utils.get_args_raw(message)
        if not args: return await utils.answer(message, "–£–∫–∞–∂–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞.")
        chat_id=utils.get_chat_id(message)
        hist=self._get_structured_history(chat_id)
        found=[f"{e['role']}: {e.get('content','')[:200]}" for e in hist if args.lower() in str(e.get("content", "")).lower()]
        if not found: await utils.answer(message, "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        else: await utils.answer(message, "\n\n".join(found[:10]))

    @loader.command()
    async def gmemoff(self, message: Message):
        """‚Äî –û—Ç–∫–ª—é—á–∏—Ç—å –ø–∞–º—è—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ"""
        chat_id=utils.get_chat_id(message)
        self.memory_disabled_chats.add(str(chat_id))
        await utils.answer(message, "–ü–∞–º—è—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ –æ—Ç–∫–ª—é—á–µ–Ω–∞.")

    @loader.command()
    async def gmemon(self, message: Message):
        """‚Äî –í–∫–ª—é—á–∏—Ç—å –ø–∞–º—è—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ"""
        chat_id=utils.get_chat_id(message)
        self.memory_disabled_chats.discard(str(chat_id))
        await utils.answer(message, "–ü–∞–º—è—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ –≤–∫–ª—é—á–µ–Ω–∞.")

    @loader.command()
    async def gmemshow(self, message: Message):
        """[auto] ‚Äî –ü–æ–∫–∞–∑–∞—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞ (–¥–æ 20 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤). auto –¥–ª—è gauto."""
        args=utils.get_args_raw(message)
        gauto_mode=args=="auto"
        chat_id=utils.get_chat_id(message)
        hist=self._get_structured_history(chat_id, gauto=gauto_mode)
        if not hist: return await utils.answer(message, "–ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞.")
        out=[]
        for e in hist[-40:]:
            role=e.get('role')
            content=utils.escape_html(str(e.get('content',''))[:300])
            if role=='user': out.append(f"{content}")
            elif role=='model': out.append(f"<b>Gemini:</b> {content}")
        text="<blockquote expandable='true'>" + "\n".join(out) + "</blockquote>"
        await utils.answer(message, text)

    @loader.command()
    async def gmodel(self, message: Message):
        """[model –∏–ª–∏ –ø—É—Å—Ç–æ] ‚Äî –£–∑–Ω–∞—Ç—å/—Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å"""
        args=utils.get_args_raw(message)
        if not args: await utils.answer(message, f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: <code>{self.config['model_name']}</code>"); return
        args_str=str(args).strip()
        self.config["model_name"]=args_str
        await utils.answer(message, f"–ú–æ–¥–µ–ª—å Gemini —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: <code>{args_str}</code>")

    @loader.command()
    async def gres(self, message: Message):
        """[auto] ‚Äî –û—á–∏—Å—Ç–∏—Ç—å –í–°–Æ –ø–∞–º—è—Ç—å. auto –¥–ª—è –≤—Å–µ–π –ø–∞–º—è—Ç–∏ gauto."""
        args=utils.get_args_raw(message)
        if args=="auto":
            if not self.gauto_conversations: return await utils.answer(message, self.strings["no_gauto_memory_to_fully_clear"])
            num_chats=len(self.gauto_conversations)
            self.gauto_conversations.clear()
            self._save_history_sync(gauto=True)
            await utils.answer(message, self.strings["gauto_memory_fully_cleared"].format(num_chats))
        elif not args:
            if not self.conversations: return await utils.answer(message, self.strings["no_memory_to_fully_clear"])
            num_chats=len(self.conversations)
            self.conversations.clear()
            self._save_history_sync(gauto=False)
            await utils.answer(message, self.strings["memory_fully_cleared"].format(num_chats))
        else:
            await utils.answer(message, self.strings["gres_usage"])
    def _configure_proxy(self):
        for var in ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY"]: os.environ.pop(var, None)
        if self.config["proxy"]:
            os.environ["http_proxy"]=self.config["proxy"]
            os.environ["https_proxy"]=self.config["proxy"]

    async def client_ready(self, client, db):
        self.client=client
        self.db=db
        self.me=await client.get_me()
        self.conversations=self._load_history_from_db(DB_HISTORY_KEY)
        self.gauto_conversations=self._load_history_from_db(DB_GAUTO_HISTORY_KEY)
        self.impersonation_chats=set(self.db.get(self.strings["name"], DB_IMPERSONATION_KEY, []))
        self.safety_settings=[{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        self._configure_proxy()
        if not self.config["api_key"]: logger.warning("Gemini: API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")

    @loader.watcher(only_incoming=True, ignore_edited=True)
    async def watcher(self, message: Message):
        if not isinstance(message, types.Message) or not hasattr(message, 'chat_id'): return
        chat_id=utils.get_chat_id(message)
        if chat_id not in self.impersonation_chats: return
        if message.out or (message.from_id and message.from_id.user_id==self.me.id) or (message.text and message.text.startswith(self.get_prefix())): return
        sender=await message.get_sender()
        if not sender or sender.bot: return
        if random.random() > self.config["impersonation_reply_chance"]: return
        parts, warnings=await self._prepare_parts(message)
        if warnings: logger.warning(f"Gauto watcher warnings: {warnings}")
        if not parts: return
        response_text=await self._send_to_gemini(message=message, parts=parts, impersonation_mode=True)
        if response_text and response_text.strip():
            await asyncio.sleep(random.uniform(1.0, 2.5))
            await message.reply(response_text.strip())
    def _load_history_from_db(self, db_key: str) -> dict:
        raw_conversations=self.db.get(self.strings["name"], db_key, {})
        if not isinstance(raw_conversations, dict):
            logger.warning(f"Gemini: –ë–î –¥–ª—è –∫–ª—é—á–∞ '{db_key}' –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞, —Å–±—Ä–∞—Å—ã–≤–∞—é.")
            raw_conversations={}; self.db.set(self.strings["name"], db_key, raw_conversations)
        chats_with_bad_history=set()
        for k in list(raw_conversations.keys()):
            v=raw_conversations[k]
            if not isinstance(v, list):
                chats_with_bad_history.add(k)
                raw_conversations[k]=[]
            else:
                filtered, bad_found=[], False
                for e in v:
                    if isinstance(e, dict) and "role" in e and "content" in e: filtered.append(e)
                    else: bad_found=True
                if bad_found: chats_with_bad_history.add(k)
                raw_conversations[k]=filtered
        if chats_with_bad_history: logger.warning(f"Gemini ({db_key}): –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏ –≤ {len(chats_with_bad_history)} —á–∞—Ç–∞—Ö. –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã.")
        return raw_conversations
    def _save_history_sync(self, gauto: bool=False):
        if getattr(self, "_db_broken", False): return
        conversations_to_save, db_key=(self.gauto_conversations, DB_GAUTO_HISTORY_KEY) if gauto else (self.conversations, DB_HISTORY_KEY)
        try: self.db.set(self.strings["name"], db_key, conversations_to_save)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ Gemini (gauto={gauto}): {e}")
            self._db_broken=True
    def _get_structured_history(self, chat_id: int, gauto: bool=False) -> list:
        conversations=self.gauto_conversations if gauto else self.conversations
        hist=conversations.get(str(chat_id), [])
        if not isinstance(hist, list):
            logger.warning(f"–ü–∞–º—è—Ç—å –¥–ª—è —á–∞—Ç–∞ {chat_id} (gauto={gauto}) –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞, —Å–±—Ä–∞—Å—ã–≤–∞—é.")
            hist=[]
            conversations[str(chat_id)]=hist
            self._save_history_sync(gauto)
        return hist
    def _update_history(self, chat_id: int, user_parts: list, model_response: str, regeneration: bool=False, message: Message=None, gauto: bool=False):
        if not self._is_memory_enabled(str(chat_id)): return
        history=self._get_structured_history(chat_id, gauto)
        now=int(asyncio.get_event_loop().time())
        user_id=get_peer_id(getattr(message, "from_id", None)) if message else self.me.id
        message_id=getattr(message, "id", None)
        user_text=" ".join([p.text for p in user_parts if hasattr(p, 'text') and p.text]) or "[–æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞]"
        if regeneration:
            for i in range(len(history) - 1, -1, -1):
                if history[i].get("role")=="model":
                    history[i].update({"content": model_response, "date": now}); break
        else:
            history.extend([{"role": "user", "type": "text", "content": user_text, "date": now, "user_id": user_id, "message_id": message_id}, {"role": "model", "type": "text", "content": model_response, "date": now}])
        max_len=self.config["max_history_length"]
        if max_len > 0 and len(history) > max_len*2: history=history[-(max_len*2):]
        conversations=self.gauto_conversations if gauto else self.conversations
        conversations[str(chat_id)]=history
        self._save_history_sync(gauto)
    def _clear_history(self, chat_id: int, gauto: bool=False):
        conversations=self.gauto_conversations if gauto else self.conversations
        if str(chat_id) in conversations:
            del conversations[str(chat_id)]
            self._save_history_sync(gauto)
    def _handle_error(self, e: Exception) -> str:
        logger.exception("Gemini execution error")
        if isinstance(e, asyncio.TimeoutError): return self.strings["api_timeout"]
        if isinstance(e, google_exceptions.GoogleAPIError):
            msg=str(e)
            if "quota" in msg.lower() or "exceeded" in msg.lower():
                model_name_match=re.search(r'key: "model"\s+value: "([^"]+)"', msg)
                model_name=model_name_match.group(1) if model_name_match else self.config['model_name']
                return 
            (
            f"‚ùóÔ∏è <b>–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç Google Gemini API –¥–ª—è –º–æ–¥–µ–ª–∏ <code>{utils.escape_html(model_name)}</code>.",
            "</b>\n\n–ß–∞—â–µ –≤—Å–µ–≥–æ —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º —Ç–∞—Ä–∏—Ñ–µ. –í—ã –º–æ–∂–µ—Ç–µ:\n ",
            "‚Ä¢ –ü–æ–¥–æ–∂–¥–∞—Ç—å, –ø–æ–∫–∞ –ª–∏–º–∏—Ç —Å–±—Ä–æ—Å–∏—Ç—Å—è (–æ–±—ã—á–Ω–æ —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏).\n ",
            "‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–æ–π —Ç–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω –≤ <a href='https://aistudio.google.com/app/billing'>Google AI Studio</a>.\n ",
            "‚Ä¢ –£–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ –ª–∏–º–∏—Ç–∞—Ö <a href='https://ai.google.dev/gemini-api/docs/rate-limits'>–∑–¥–µ—Å—å</a>.\n\n",
            "<b>–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:</b>\n<code>{utils.escape_html(msg)}</code>"
            )
        
            if "500 An internal error has occurred" in msg: return 
            (
            "‚ùóÔ∏è <b>–û—à–∏–±–∫–∞ 500 –æ—Ç Google API.</b>\n"
            "–≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç –º–µ–¥–∏–∞ (—Ñ–∞–π–ª –∏–ª–∏ –µ—â–µ —á—Ç–æ —Ç–æ) –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –æ—Ç–ø—Ä–∞–≤–∏–ª, –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.\n"
            "–¢–∞–∫–æ–µ —Å–ª—É—á–∞–µ—Ç—Å—è, –ø–æ —Ç–∞–∫–æ–π –ø—Ä–∏—á–∏–Ω–µ:\n  "
            "‚Ä¢ –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è Gemini/–ì—É–≥–ª–æ–º.\n  "
            "‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–π —Å–±–æ–π –Ω–∞ —Å–µ—Ä–≤–µ—Ä–∞—Ö Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–∑–∂–µ."
            )
        
            if "User location is not supported for the API use" in msg or "location is not supported" in msg: return (
            "‚ùóÔ∏è <b>–í –¥–∞–Ω–Ω–æ–º —Ä–µ–≥–∏–æ–Ω–µ Gemini API –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω.</b>\n",
            "–°–∫–∞—á–∞–π—Ç–µ VPN (–¥–ª—è –ø–∫/—Ç–µ–ª) –∏–ª–∏ –ø–æ—Å—Ç–∞–≤—å—Ç–µ –ø—Ä–æ–∫—Å–∏ (–ø–ª–∞—Ç–Ω—ã–π/–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π).\n",
            "–ò–ª–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π <a href=\"https://t.me/SenkoGuardianModules/23\">–≤–æ—Ç —Ç—É—Ç</a>\n",
            "–ê –¥–ª—è —Ç–µ—Ö —É –∫–æ–≥–æ UserLand –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è <a href=\"https://t.me/SenkoGuardianModules/35\">—Ç—É—Ç</a>\n"
            )
        
            if "API key not valid" in msg: return self.strings["no_api_key"]
            if "blocked" in msg.lower(): return self.strings["blocked_error"].format(utils.escape_html(msg))
            return self.strings["api_error"].format(utils.escape_html(msg))
        if isinstance(e, (OSError, aiohttp.ClientError, socket.timeout)): return "‚ùóÔ∏è <b>–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞:</b>\n<code>{}</code>".format(utils.escape_html(str(e)))
        msg=str(e)
        if "No API_KEY or ADC found" in msg or "GOOGLE_API_KEY environment variable" in msg or "genai.configure(api_key" in msg: return
        (
        "‚ùóÔ∏è <b>API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω.</b>\n "
        "–ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á –º–æ–∂–Ω–æ —Ç—É—Ç: <a href=\"https://aistudio.google.com/apikey\">https://aistudio.google.com/apikey</a>\n "
        "<b>–ü–æ—Å—Ç–∞–≤–∏—Ç—å API –∫–ª—é—á —Å—é–¥–∞</b>: <code>.cfg gemini api_key</code>"
        )
        return self.strings["generic_error"].format(utils.escape_html(str(e)))

    async def _prepare_parts(self, message: Message, custom_text: str=None):
        final_parts, warnings=[], []
        prompt_text_chunks=[]
        user_args=custom_text if custom_text is not None else utils.get_args_raw(message)
        reply=await message.get_reply_message()
        if reply and reply.text:
            try:
                reply_sender=await reply.get_sender()
                reply_author_name=get_display_name(reply_sender) if reply_sender else "Unknown"
                prompt_text_chunks.append(f"{reply_author_name}: {reply.text}")
            except Exception: prompt_text_chunks.append(f"–û—Ç–≤–µ—Ç –Ω–∞: {reply.text}")
        try:
            current_sender=await message.get_sender()
            current_user_name=get_display_name(current_sender) if current_sender else "User"
            prompt_text_chunks.append(f"{current_user_name}: {user_args or ''}")
        except Exception: prompt_text_chunks.append(f"–ó–∞–ø—Ä–æ—Å: {user_args or ''}")
        media_source=message if message.media or message.sticker else reply
        has_media=bool(media_source and (media_source.media or media_source.sticker))
        if has_media:
            MAX_IMAGE_SIZE=48 * 1024 * 1024
            if media_source.sticker and hasattr(media_source.sticker, 'mime_type') and media_source.sticker.mime_type=='application/x-tgsticker':
                alt_text=next((attr.alt for attr in media_source.sticker.attributes if isinstance(attr, types.DocumentAttributeSticker)), "?")
                prompt_text_chunks.append(f"[–û—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∏–∫–µ—Ä: {alt_text}]")
            else:
                media=media_source.media
                mime_type, filename="application/octet-stream", "file"
                if media_source.photo: mime_type="image/jpeg"
                elif hasattr(media_source, "document") and media_source.document:
                    mime_type=getattr(media_source.document, "mime_type", mime_type)
                    doc_attr=next((attr for attr in media_source.document.attributes if isinstance(attr, DocumentAttributeFilename)), None)
                    if doc_attr: filename=doc_attr.file_name
                if mime_type.startswith("image/"):
                    try:
                        byte_io=io.BytesIO()
                        await self.client.download_media(media, byte_io)
                        if byte_io.tell() < MAX_IMAGE_SIZE:
                            byte_io.seek(0)
                            final_parts.append(glm.Part(inline_data=glm.Blob(mime_type=mime_type, data=byte_io.getvalue())))
                        else: warnings.append(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ '{filename}' —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ (> {MAX_IMAGE_SIZE // 1024 // 1024} –ú–ë).")
                    except Exception as e: warnings.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è '{filename}': {e}")
                elif mime_type in self.TEXT_MIME_TYPES or filename.split('.')[-1] in ('txt', 'py', 'js', 'json', 'md', 'html', 'css', 'sh'):
                    try:
                        MAX_TEXT_SIZE=1 * 1024 * 1024
                        if hasattr(media_source, "document") and media_source.document and media_source.document.size > MAX_TEXT_SIZE: warnings.append(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª '{filename}' —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (> {MAX_TEXT_SIZE // 1024 // 1024} –ú–ë).")
                        else:
                            byte_io=io.BytesIO()
                            await self.client.download_media(media, byte_io)
                            byte_io.seek(0)
                            file_content=byte_io.read().decode('utf-8')
                            prompt_text_chunks.insert(0, f"[–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ '{filename}']: \n```\n{file_content}\n```")
                    except UnicodeDecodeError: warnings.append(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª '{filename}' –∫–∞–∫ —Ç–µ–∫—Å—Ç (–æ—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏).")
                    except Exception as e: warnings.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ '{filename}': {e}")
                elif mime_type.startswith(("video/", "audio/")):
                    input_path, output_path=None, None
                    try:
                        with tempfile.NamedTemporaryFile(suffix=f".{filename.split('.')[-1]}", delete=False) as temp_in: input_path=temp_in.name
                        await self.client.download_media(media, input_path)
                        if os.path.getsize(input_path) > MAX_FFMPEG_SIZE:
                            warnings.append(f"‚ö†Ô∏è –ú–µ–¥–∏–∞—Ñ–∞–π–ª '{filename}' —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (> {MAX_FFMPEG_SIZE // 1024 // 1024} –ú–ë)."); raise StopIteration
                        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_out: output_path=temp_out.name
                        ffmpeg_cmd=["ffmpeg", "-y", "-i", input_path, "-c:v", "libx264", "-c:a", "aac", "-pix_fmt", "yuv420p", "-movflags", "+faststart", output_path]
                        process=await asyncio.create_subprocess_exec(*ffmpeg_cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
                        _, stderr=await process.communicate()
                        if process.returncode !=0:
                            stderr_str=stderr.decode()
                            if "Invalid data found when processing input" in stderr_str: warnings.append(f"‚ö†Ô∏è –§–∞–π–ª '{filename}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–º –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
                            else: warnings.append(f"‚ö†Ô∏è <b>–û—à–∏–±–∫–∞ FFmpeg:</b>\n–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å '{filename}'. –î–µ—Ç–∞–ª–∏:\n<code>{utils.escape_html(stderr_str)}</code>")
                            raise StopIteration
                        with open(output_path, "rb") as f: converted_bytes=f.read()
                        final_parts.append(glm.Part(inline_data=glm.Blob(mime_type="video/mp4", data=converted_bytes)))
                    except StopIteration: pass
                    except Exception as e: warnings.append(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ–¥–∏–∞ '{filename}': {e}")
                    finally:
                        if input_path and os.path.exists(input_path): os.remove(input_path)
                        if output_path and os.path.exists(output_path): os.remove(output_path)
        if not user_args and has_media and not final_parts and not any("[–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞" in chunk for chunk in prompt_text_chunks): prompt_text_chunks.append(self.strings["media_reply_placeholder"])
        full_prompt_text="\n".join(chunk for chunk in prompt_text_chunks if chunk and chunk.strip()).strip()
        if full_prompt_text: final_parts.insert(0, glm.Part(text=full_prompt_text))
        return final_parts, warnings
    def _markdown_to_html(self, text: str) -> str:
        def heading_replacer(match): level=len(match.group(1)); title=match.group(2).strip(); indent="   " * (level - 1); return f"{indent}<b>{title}</b>"
        text=re.sub(r"^(#+)\s+(.*)", heading_replacer, text, flags=re.MULTILINE)
        def list_replacer(match): indent=match.group(1); return f"{indent}‚Ä¢ "
        text=re.sub(r"^([ \t]*)[-*+]\s+", list_replacer, text, flags=re.MULTILINE)
        md=MarkdownIt("commonmark", {"html": True, "linkify": True}); md.enable("strikethrough"); md.disable("hr"); md.disable("heading"); md.disable("list")
        html_text=md.render(text)
        def format_code(match):
            lang=utils.escape_html(match.group(1).strip()); code=utils.escape_html(match.group(2).strip())
            return f'<pre><code class="language-{lang}">{code}</code></pre>' if lang else f'<pre><code>{code}</code></pre>'
        html_text=re.sub(r"```(.*?)\n([\s\S]+?)\n```", format_code, html_text)
        html_text=re.sub(r"<p>(<pre>[\s\S]*?</pre>)</p>", r"\1", html_text, flags=re.DOTALL)
        html_text=html_text.replace("<p>", "").replace("</p>", "\n").strip()
        return html_text
    def _format_response_with_smart_separation(self, text: str) -> str:
        pattern=r"(<pre.*?>[\s\S]*?</pre>)"; parts=re.split(pattern, text, flags=re.DOTALL); result_parts=[]
        for i, part in enumerate(parts):
            if not part or part.isspace(): continue
            if i % 2==1: result_parts.append(part.strip())
            else:
                stripped_part=part.strip()
                if stripped_part: result_parts.append(f'<blockquote expandable="true">{stripped_part}</blockquote>')
        return "\n".join(result_parts)
    def _get_inline_buttons(self, chat_id, base_message_id): return [[{"text": self.strings["btn_clear"], "callback": self._clear_callback, "args": (chat_id,)}, {"text": self.strings["btn_regenerate"], "callback": self._regenerate_callback, "args": (base_message_id, chat_id)}]]

    async def _safe_del_msg(self, msg, delay=1):
        await asyncio.sleep(delay)
        try: await self.client.delete_messages(msg.chat_id, msg.id)
        except Exception as e: logger.warning(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

    async def _clear_callback(self, call: InlineCall, chat_id: int):
        self._clear_history(chat_id, gauto=False)
        await call.edit(self.strings["memory_cleared"], reply_markup=None)

    async def _send_to_gemini(self, message, parts: list, regeneration: bool=False, call: InlineCall=None, status_msg=None, chat_id_override: int=None, impersonation_mode: bool=False, use_url_context: bool=False, display_prompt: str=None):
        msg_obj=None
        if regeneration:
            chat_id=chat_id_override; base_message_id=message
            try: msg_obj=await self.client.get_messages(chat_id, ids=base_message_id)
            except Exception: msg_obj=None
        else:
            chat_id=utils.get_chat_id(message); base_message_id=message.id; msg_obj=message
        try:
            if not self.config["api_key"]:
                if not impersonation_mode and status_msg: await utils.answer(status_msg, self.strings['no_api_key'])
                return None if impersonation_mode else ""
            genai.configure(api_key=self.config["api_key"]); tools_list=[]
            if use_url_context:
                try: tools_list.append(genai.types.Tool(url_context=genai.types.UrlContext()))
                except AttributeError: logger.error("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç UrlContext –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤–∞—à–µ–π –≤–µ—Ä—Å–∏–µ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.")
            system_instruction_to_use=None; api_history_content=[]
            if impersonation_mode:
                my_name=get_display_name(self.me); chat_history_text=await self._get_recent_chat_text(chat_id); system_instruction_to_use=self.config["impersonation_prompt"].format(my_name=my_name, chat_history=chat_history_text)
                raw_history=self._get_structured_history(chat_id, gauto=True); api_history_content=[glm.Content(role=e["role"], parts=[glm.Part(text=e['content'])]) for e in raw_history]
            else:
                system_instruction_val=self.config["system_instruction"]; system_instruction_to_use=(system_instruction_val.strip() if isinstance(system_instruction_val, str) else "") or None
                raw_history=self._get_structured_history(chat_id, gauto=False)
                if regeneration: raw_history=raw_history[:-2]
                api_history_content=[glm.Content(role=e["role"], parts=[glm.Part(text=e['content'])]) for e in raw_history]
            model=genai.GenerativeModel(self.config["model_name"],safety_settings=self.safety_settings,system_instruction=system_instruction_to_use)
            full_request_content=list(api_history_content)
            if not impersonation_mode:
                from datetime import datetime
                try: user_timezone=pytz.timezone(self.config["timezone"])
                except pytz.UnknownTimeZoneError: user_timezone=pytz.utc
                now=datetime.now(user_timezone); time_str=now.strftime("%Y-%m-%d %H:%M:%S %Z"); time_note=f"[System note: Current time is {time_str}]"
                text_part_found=False
                for p in parts:
                    if hasattr(p, 'text'): p.text=f"{time_note}\n\n{p.text}"; text_part_found=True; break
                if not text_part_found: parts.insert(0, glm.Part(text=time_note))
            if regeneration:
                current_turn_parts,request_text_for_display=self.last_requests.get(f"{chat_id}:{base_message_id}", (parts, "[—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è]"))
            else:
                current_turn_parts=parts; request_text_for_display=display_prompt or (self.strings["media_reply_placeholder"] if any("inline_data" in str(p) for p in parts) else ""); self.last_requests[f"{chat_id}:{base_message_id}"]=(current_turn_parts, request_text_for_display)
            if current_turn_parts: full_request_content.append(glm.Content(role="user", parts=current_turn_parts))
            if not full_request_content and not system_instruction_to_use:
                if not impersonation_mode and status_msg: await utils.answer(status_msg, self.strings["no_prompt_or_media"])
                return None if impersonation_mode else ""
            response=await asyncio.wait_for(model.generate_content_async(full_request_content,tools=tools_list or None),timeout=GEMINI_TIMEOUT)
            result_text,was_successful="",False
            try:
                if response.prompt_feedback.block_reason: result_text=f"üö´ <b>–ó–∞–ø—Ä–æ—Å –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Google.</b>\n–ü—Ä–∏—á–∏–Ω–∞: <code>{response.prompt_feedback.block_reason.name}</code>."
            except AttributeError: pass
            if not result_text:
                try:
                    result_text=response.text; was_successful=True
                except ValueError:
                    reason="–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞"
                    try:
                        if response.candidates: reason=response.candidates[0].finish_reason.name
                    except(IndexError, AttributeError): pass
                    result_text=f"‚ùóÔ∏è Gemini –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.\n–ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: <code>{reason}</code>."
            if was_successful and self._is_memory_enabled(str(chat_id)): self._update_history(chat_id, current_turn_parts, result_text, regeneration, msg_obj, gauto=impersonation_mode)
            if impersonation_mode: return result_text if was_successful else None
            text_from_file_present=any(p.text.startswith("[–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞") for p in parts if hasattr(p, 'text'))
            binary_file_present=any("inline_data" in str(p) for p in parts)
            file_processed=text_from_file_present or binary_file_present
            hist_len_pairs=len(self._get_structured_history(chat_id, gauto=False)) // 2; limit=self.config["max_history_length"]; mem_indicator=self.strings["memory_status_unlimited"].format(hist_len_pairs) if limit <= 0 else self.strings["memory_status"].format(hist_len_pairs, limit)
            tool_indicator=""; 
            if use_url_context: tool_indicator+="üîó "
            if file_processed: tool_indicator+="üìé "
            question_html=f"<blockquote>{utils.escape_html(request_text_for_display[:200])}</blockquote>"; response_html=self._markdown_to_html(result_text); formatted_body=self._format_response_with_smart_separation(response_html)
            header=f"{tool_indicator.strip()}\n{mem_indicator}\n\n{self.strings['question_prefix']}\n{question_html}\n\n{self.strings['response_prefix']}\n"; text_to_send=f"{header}{formatted_body}"
            buttons=self._get_inline_buttons(chat_id, base_message_id) if self.config["interactive_buttons"] else None
            if len(text_to_send) > 4096:
                file_content=(f"–í–æ–ø—Ä–æ—Å: {display_prompt}\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n–û—Ç–≤–µ—Ç Gemini:\n{result_text}")
                file=io.BytesIO(file_content.encode("utf-8")); file.name="Gemini_response.txt"
                if call:
                    await call.answer("–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ—Ç–ø—Ä–∞–≤–ª—è—é —Ñ–∞–π–ª–æ–º...", show_alert=False); await self.client.send_file(call.chat_id, file, caption=self.strings["response_too_long"], reply_to=call.message_id); await call.edit(f"‚úÖ {self.strings['response_too_long']}", reply_markup=None)
                elif status_msg:
                    await status_msg.delete(); await self.client.send_file(chat_id, file, caption=self.strings["response_too_long"], reply_to=base_message_id)
            else:
                if call: await call.edit(text_to_send, reply_markup=buttons)
                elif status_msg: await utils.answer(status_msg, text_to_send, reply_markup=buttons)
        except Exception as e:
            error_text=self._handle_error(e)
            if impersonation_mode: logger.error(f"Gemini auto-reply error: {error_text}")
            elif call: await call.edit(error_text, reply_markup=None)
            elif status_msg: await utils.answer(status_msg, error_text)
        return None if impersonation_mode else ""

    async def _regenerate_callback(self, call: InlineCall, original_message_id: int, chat_id: int):
        key=f"{chat_id}:{original_message_id}"; last_request_tuple=self.last_requests.get(key)
        if not last_request_tuple: return await call.answer(self.strings["no_last_request"], show_alert=True)
        last_parts, display_prompt=last_request_tuple; use_url_context=bool(re.search(r'https?://\S+', display_prompt))
        await self._send_to_gemini(message=original_message_id, parts=last_parts, regeneration=True, call=call, chat_id_override=chat_id, use_url_context=use_url_context, display_prompt=display_prompt)

    async def _get_recent_chat_text(self, chat_id: int, count: int=None, skip_last: bool=False) -> str:
        history_limit=count or self.config["impersonation_history_limit"]; fetch_limit=history_limit + 1 if skip_last else history_limit; chat_history_lines=[]
        try:
            messages=await self.client.get_messages(chat_id, limit=fetch_limit)
            if skip_last and messages: messages=messages[1:]
            for msg in messages:
                if not msg.text and not msg.sticker and not msg.photo and not (msg.media and not hasattr(msg.media, "webpage")): continue
                sender=await msg.get_sender(); sender_name=get_display_name(sender) if sender else "Unknown"; text_content=msg.text or ""
                if msg.sticker and hasattr(msg.sticker, 'attributes'):
                    alt_text=next((attr.alt for attr in msg.sticker.attributes if isinstance(attr, types.DocumentAttributeSticker)), None)
                    text_content+=f" [–°—Ç–∏–∫–µ—Ä: {alt_text or '?'}]"
                elif msg.photo: text_content+=" [–§–æ—Ç–æ]"
                elif msg.document and not hasattr(msg.media, "webpage"): text_content+=" [–§–∞–π–ª]"
                if text_content.strip(): chat_history_lines.append(f"{sender_name}: {text_content.strip()}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç–∞: {e}")
        return "\n".join(reversed(chat_history_lines))

    def _is_memory_enabled(self, chat_id: str) -> bool: return chat_id not in self.memory_disabled_chats
    def _disable_memory(self, chat_id: int): self.memory_disabled_chats.add(str(chat_id))
    def _enable_memory(self, chat_id: int): self.memory_disabled_chats.discard(str(chat_id))
# A
# :^
# –Ω–µ –Ω—É —Ç—É—Ç –±–µ—Å–ø—Ä–µ–¥–µ–ª –∫–∞–∫–æ–π —Ç–æ
# –Ω—É –±–æ–ª–µ–µ –º–µ–Ω–µ–µ –Ω–∞–ø–∏—Å–∞–ª
# –∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ
# –∫—Ç–æ –ø—Ä–æ—á–∏—Ç–∞–ª —Ç–æ—Ç –≥–µ–π)
